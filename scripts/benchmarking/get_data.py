# -*- coding: utf-8 -*-
"""Get data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fu-vQOSNFS2aapMPB-3x8XIRpAYlKvtg
"""

from google.colab import drive
drive.mount('/content/drive')
!folder=19_06 && cp drive/MyDrive/ITMO/samovar/validation/$folder ./ -r && mv ./$folder ./data

!wget https://ftp.ncbi.nih.gov/pub/taxonomy/new_taxdump/new_taxdump.tar.gz
!tar -xvzf new_taxdump.tar.gz
!mkdir ncbi && mv *dmp ncbi/
!rm *tar*

"""## Import modules"""

import pandas as pd
import numpy as np
import os
import json
import requests
import re
!pip install taxonomy
import taxonomy

"""## Functions"""

if False:
  def get_GMrepo_runs(mesh_id = 'D006262'):
    # code from https://github.com/evolgeniusteam/GMrepoProgrammableAccess/blob/master/programmable-access/
    pheno_query = {'mesh_id':mesh_id}
    url = 'http://gmrepo.humangut.info/api/countAssociatedRunsByPhenotypeMeshID'
    pheno = requests.post(url, data=json.dumps(pheno_query))
    pheno_cont = pheno.json()

    ## -- the resulting variable is a vector --
    phenotyp_nr_assoc_runs = pd.DataFrame(pheno.json())
    print('Number of associated runs:', len(phenotyp_nr_assoc_runs))
    return phenotyp_nr_assoc_runs
  get_GMrepo_runs().head()

def read_kaiju_raw(file_path):
  df = pd.read_table(file_path, header = None)
  df.columns = ["classified", "seq", "score", "taxID", "N"]
  return(df)

read_kaiju_raw("data/hiseq_kaiju.log").head()

def read_kraken1_raw(file_path):
  df = pd.read_table(file_path, header = None)
  df.columns = ["classified", "seq", "taxID", "length", "k-mer"]
  return(df)

read_kraken1_raw("data/hiseq_k1.log").head()

def read_kraken2_raw(file_path):
  df = pd.read_table(file_path, header = None)
  df.columns = ["classified", "seq", "taxa", "length", "k-mer"]
  df["length"] = [re.sub("\|.*", "", i)for i in df["length"] ]
  df["taxID"] = [re.search(r'(?<=taxid )[0-9]*',i).group(0) for i in df["taxa"]]
  df["taxa"] = [re.sub(r' \(.*', "", i) for i in df["taxa"]]
  return(df)

read_kraken2_raw("data/hiseq_k2.log").head()

def read_krakenu_raw(file_path):
  df = pd.read_table(file_path, header = None)
  df.columns = ["classified", "seq", "taxID", "length", "k-mer"]
  return(df)

read_krakenu_raw("data/hiseq_ku.log").head()

def read_mp4_raw(file_path):
  df = pd.read_table(file_path, header = None)
  df["seq"] = [re.sub("\/.*", "", i) for i in df[0]]
  return df

read_mp4_raw("data/hiseq_mpa.log").head()

read_raw = {
    "kraken": read_kraken1_raw,
    "kraken1": read_kraken1_raw,
    "kraken2": read_kraken2_raw,
    "krakenunique": read_krakenu_raw,
    "krakenu": read_krakenu_raw,
    "metaphaln": read_mp4_raw,
    "mpa": read_mp4_raw,
    "mp4": read_mp4_raw,
    "kaiju": read_kaiju_raw
}

def read_annotation(file_path_type: dict, trimmed = True):
  #file_path_type: {path: type}
  res = pd.DataFrame()
  for a, b in file_path_type.items():
    df = read_raw.get(b)(a).set_index("seq")
    if trimmed:
      df = df[["taxID"]]

    df.columns = [i + "_" + b if i != "seq" else "seq" for i in df.columns]
    res = pd.concat([res, df], axis = 1)
  return res

read_annotation({
    "data/hiseq_k2.log": "kraken2",
    "data/hiseq_k1.log": "kraken1",
    "data/hiseq_ku.log": "krakenu"
}).head()

tax = taxonomy.Taxonomy.from_ncbi("./ncbi")

class annotation:
  #dictionary
  read_raw = {
    "kraken": read_kraken1_raw,
    "kraken1": read_kraken1_raw,
    "kraken2": read_kraken2_raw,
    "krakenunique": read_krakenu_raw,
    "krakenu": read_krakenu_raw,
    "metaphaln": read_mp4_raw,
    "mpa": read_mp4_raw,
    "mp4": read_mp4_raw,
    "kaiju": read_kaiju_raw
  }

  #init
  def __init__(self, file_path_type:dict, get_true_annotation = None):
    self.DataFrame = pd.DataFrame()
    for a, b in file_path_type.items():
      df = annotation.read_raw.get(b)(a).set_index("seq").astype({"taxID": 'string'})
      df.columns = [i + "_" + b for i in df.columns]
      self.DataFrame = pd.concat([self.DataFrame, df], axis = 1)

    if get_true_annotation is not None:
      self.true_annotation = [re.search(get_true_annotation, i).group(0) for i in self.DataFrame.index]

    set_columns = []
    for name, column in self.tr().items():
      set_columns += list(set(column))

    self.annotation_list = annotation.list2set(set_columns)
    self.true_annotation_list = annotation.list2set(self.true_annotation)
    self.rank = annotation.list2set([*self.annotation_list, *self.true_annotation_list])

  # true annotation
  def true_annotation_unique (self):
    return set(self.true_annotation)

  def true_annotation_rename(self, change_dict:dict):
    self.true_annotation = [change_dict.get(TA) if TA in change_dict.keys() else "" for TA in self.true_annotation]

  # expand annotation levels
  def rank_annotation(self, rank = "species"):
    rank_list = [annotation.rank(j, rank) for j in self.rank]
    rank_dict = dict(zip(self.rank, rank_list))
    return rank_annotation(rank).make(self.full(), rank_dict)

  def expand_annotation(self, rank = ["species"]):
    full_rank_annotation = expand_annotation()
    for i in rank:
      full_rank_annotation.add(self.rank_annotation(i))

    return full_rank_annotation

  def correct_annotations(self, rank = "species"):
    return pd.DataFrame(self.rank_annotation(rank).correct_annotation().annotation.value_counts())


  # forms
  def full(self):
    tmp = self.tr()
    tmp["true"] = self.true_annotation
    return tmp

  def tr(self):
    return self.DataFrame.copy().filter(regex="taxID.*")

  #misc
  def list2set(a:list):
    return list(set([str(i) for i in a]))

  def list2rank(a, at_rank):
    b = annotation.list2set(a)
    return [tax.node(i) for i in b]

  def rank(j,i):
    if j == "0":
      return "0"
    tmp = tax.parent(j, at_rank = i)
    if tmp is not None:
      return str(tmp.id)
    else:
      return None

  def export(self, file = False):
    df_return = self.DataFrame.loc[:, [col for col in self.DataFrame if col.startswith('taxID')]]
    df_return["length"] = self.DataFrame.loc[:, [col for col in self.DataFrame if col.startswith('length')][1] ]
    df_return["true"] = self.true_annotation
    if file != False:
      df_return.to_csv(file)
    return(df_return)



class rank_annotation:

  #prepare
  def __init__(self, rank):
    self.rank = rank
    self.annotation = pd.DataFrame()

  def add(self, name, annotation):
    self.annotation[name] = annotation

  def make(self, annotation: pd.DataFrame, rank_dict: dict):
    for name, column in annotation.items():
      self.add(str(name), [rank_dict.get(TA) for TA in column])
    self.reindex(annotation.index)
    return self

  def reindex(self, index):
    self.annotation.index = index

  #split and eval
  def y(self):
    return self.annotation["true"]

  def x(self):
    return self.annotation.copy().drop("true", axis = 1)

  def correct_annotation(self):
    tmp = rank_annotation(self.rank)

    for name, column in self.x().items():
      tmp.add(str(name), pd.DataFrame(column == self.y()))

    tmp.reindex(self.annotation.index)
    return tmp




class expand_annotation:

  def __init__(self):
    self.rank_annotation = {}

  def add(self, rank_annotation):
    self.rank_annotation[rank_annotation.rank] = rank_annotation

  def get(self, rank):
    return self.rank_annotation[rank]

"""## Import data"""

df = annotation({
    "data/hiseq_k1.log": "kraken1",
    "data/hiseq_k2.log": "kraken2",
    "data/hiseq_ku.log": "krakenu"
}, get_true_annotation=".*(?=.fna)")

df.true_annotation_rename({
    'Ecoli': '511145',
    'Hsap': '9606',
    'Phix': '2886930',
    'Scer': '559292'
})

df.correct_annotations()

df.export("toy_matrix.csv")

"""## Тесты"""

# add https://github.com/rrwick/Metagenomics-Index-Correction